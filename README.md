# ğŸ¥ Medical AI Research Assistant

A fine-tuned GPT-Neo 2.7B model trained on PubMed and ClinicalTrials.gov data for medical research assistance.

## ğŸ¯ Overview

This project fine-tunes a large language model (GPT-Neo 2.7B) on medical research data to create an intelligent assistant capable of:
- Answering medical research questions
- Analyzing clinical trial data
- Providing evidence-based medical insights
- Searching and referencing medical literature

## ğŸš€ Model Information

- **Base Model**: [EleutherAI GPT-Neo 2.7B](https://huggingface.co/EleutherAI/gpt-neo-2.7B)
- **Fine-tuned Model**: [abmodi/pubmed-2.5B](https://huggingface.co/abmodi/pubmed-2.5B)
- **Parameters**: 2.7 billion
- **Training Data**: 702 medical research articles and clinical trials
- **Training Device**: Apple M3 Ultra with MPS acceleration

## ğŸ“Š Dataset

The model was trained on a comprehensive medical dataset including:
- **PubMed Articles**: Research papers from various medical journals
- **Clinical Trials**: Data from ClinicalTrials.gov
- **Categories**: Multiple medical specialties and research areas
- **Time Range**: 2024 data with historical context

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8+
- PyTorch
- Transformers library
- SQLite3

### Setup
```bash
# Clone the repository
git clone https://github.com/yourusername/medical-ai-research-assistant.git
cd medical-ai-research-assistant

# Install dependencies
pip install -r requirements.txt

# Download the fine-tuned model (optional - will download automatically)
# The model is available on Hugging Face: abmodi/pubmed-2.5B
```

## ğŸ® Usage

### 1. Interactive Medical Assistant
```bash
python3 medical_ai_assistant_gpt_neo.py
```

Start an interactive chat session where you can ask medical questions and get AI-powered responses.

### 2. Model Testing
```bash
python3 test_gpt_neo_model.py
```

Run comprehensive tests to evaluate model performance on various medical questions.

### 3. Database Management
```bash
python3 database.py
```

Manage your medical research database, add new articles, and search existing data.

## ğŸ“ Project Structure

```
medical-ai-research-assistant/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ database.py                         # Database management
â”œâ”€â”€ pubmed_api.py                       # PubMed API integration
â”œâ”€â”€ clinicaltrials_api.py               # ClinicalTrials.gov API
â”œâ”€â”€ fine_tune_gpt_neo_2_7b_simple.py   # Model fine-tuning script
â”œâ”€â”€ medical_ai_assistant_gpt_neo.py     # Interactive assistant
â”œâ”€â”€ test_gpt_neo_model.py              # Model testing suite
â”œâ”€â”€ pubmed_data.db                      # SQLite database
â”œâ”€â”€ gpt-neo-2.7b-medical-finetuned/    # Fine-tuned model files
â””â”€â”€ docs/                              # Documentation
    â”œâ”€â”€ GPT_NEO_2_7B_SUCCESS_REPORT.md
    â””â”€â”€ LARGE_MODELS_SUMMARY.md
```

## ğŸ§ª Model Performance

The fine-tuned model demonstrates:
- **Training Loss**: Converged from 2.16 to 1.45
- **Generation Speed**: ~30 seconds per response on M3 Ultra
- **Medical Accuracy**: High relevance for medical terminology
- **Context Understanding**: Good comprehension of medical research context

## ğŸ”§ Fine-tuning Process

The model was fine-tuned using:
- **Framework**: Hugging Face Transformers
- **Training Strategy**: Causal language modeling
- **Optimization**: AdamW optimizer with cosine learning rate
- **Hardware**: Apple M3 Ultra with MPS acceleration
- **Memory Management**: Gradient checkpointing and accumulation

## ğŸ“š API Integration

### PubMed API
- Searches medical literature from PubMed
- Retrieves abstracts, authors, and metadata
- Supports date range and keyword filtering

### ClinicalTrials.gov API
- Accesses clinical trial data
- Retrieves trial phases, status, and outcomes
- Supports condition and intervention filtering

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Areas for Contribution
- Additional medical data sources
- Model performance improvements
- User interface enhancements
- Documentation improvements

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [EleutherAI](https://www.eleuther.ai/) for the GPT-Neo model
- [Hugging Face](https://huggingface.co/) for the Transformers library
- [PubMed](https://pubmed.ncbi.nlm.nih.gov/) for medical literature data
- [ClinicalTrials.gov](https://clinicaltrials.gov/) for clinical trial data

## ğŸ“ Contact

- **GitHub**: [@yourusername](https://github.com/yourusername)
- **Hugging Face**: [@abmodi](https://huggingface.co/abmodi)
- **Email**: your.email@example.com

## ğŸ† Achievements

âœ… Successfully fine-tuned 2.7B parameter model on medical data  
âœ… Trained on Apple Silicon with MPS acceleration  
âœ… Published model on Hugging Face Hub  
âœ… Created comprehensive medical AI system  
âœ… Built interactive assistant and testing tools  

## ğŸ”® Future Roadmap

- [ ] Web interface for the medical assistant
- [ ] API endpoints for model integration
- [ ] Support for additional medical data sources
- [ ] Model quantization for mobile deployment
- [ ] Multi-language support for medical terminology
- [ ] Integration with electronic health records

---

**â­ If you find this project helpful, please give it a star!**
